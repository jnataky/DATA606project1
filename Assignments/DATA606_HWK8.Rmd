---
title: "Chapter 8 - Introduction to Linear Regression"
author: "Jered Ataky"
date: "2020-10-20"
output:
    pdf_document:
        extra_dependencies: ["geometry", "multicol", "multirow", "xcolor"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Nutrition at Starbucks, Part I.** (8.22, p. 326) The scatterplot below shows the relationship between the number of calories and amount of carbohydrates (in grams) Starbucks food menu items contain. Since Starbucks only lists the number of calories on the display items, we are interested in predicting the amount of carbs a menu item has based on its calorie content.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="33%", fig.height=4}

library(tidyverse)
library(openintro)
# load data ---------------------------------------------------------
starbucks <- read.csv("https://github.com/jbryer/DATA606Fall2019/raw/master/course_data/starbucks.csv")
# model calories vs. carbos -----------------------------------------
m_carb_cals <- lm(carb ~ calories, data = starbucks)
# plot calories vs. carbos ------------------------------------------
par(mar = c(3.5, 4, 1, 0.5), las = 1, mgp = c(2.5, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)
plot(carb ~ calories, data = starbucks, 
     pch = 19, col = COL[1,2], 
     xlab = "Calories", ylab = "Carbs (grams)", axes = FALSE)
axis(1)
axis(2, at = seq(20, 80, 20))
box()
abline(m_carb_cals, col = COL[2], lwd = 2)
# plot residuals ----------------------------------------------------
par(mar = c(3.5, 4, 1, 0.5), las = 1, mgp = c(2.5, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)

plot(m_carb_cals$residuals ~ starbucks$calories,
     xlab = "Calories", ylab = "Residuals", 
     col = COL[1,2], pch = 19,
     ylim = c(-30, 30), axes = FALSE)
axis(1)
axis(2, at = seq(-20, 20, 20))
box()
abline(h = 0, lty = 2)
# histogram of residuals --------------------------------------------
par(mar = c(3.5, 2.5, 0.5, 0.5), las = 1, mgp = c(2.5, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)

hist(m_carb_cals$residuals,
     col = COL[1], 
     xlab = "Residuals", ylab = "", main = "", 
     axes = FALSE, xlim = c(-40,40))
axis(1, at = seq(-40, 40, 20))
axis(2)
```

(a) Describe the relationship between number of calories and amount of carbohydrates (in grams) that Starbucks food menu items contain.
(b) In this scenario, what are the explanatory and response variables?
(c) Why might we want to fit a regression line to these data?
(d) Do these data meet the conditions required for fitting a least squares line?


## Solution 1

(a)

the relationship between number of calories and
amount of carbohydrates (in grams) that Starbucks food menu items contain
is a linear relationship.
As the amount of calories increases, the amount of carbohydrates (in grams)
increases as well.

```{r}

m_carb_cals <- lm(carb ~ calories, data = starbucks)

print(m_carb_cals)

```

amount of carbohydrates (in grams) = 8.944 + 0.106*(calories)

(b)

The explanatory variable is "calories" and 
the response variable is "amount of carbohydrates (in grams)".

(c)

The two variables are associated. We might want to fit a regression
to predict the amount of carbohydrates(in grams) based on the number of 
calories.

(d)

I would say that all the conditions required are not met:

**Linearity:** The data show a linear trend from lm plot, condition met.

**Nearly normal residuals** From the histogram we can see that
the data are skewed but it is nearly normal.

**Constant variability:** The data better in lower values than upper ones.
There are more residuals as the calories increase. Condition not met. 



--------------------------------------------------------------------------------

\clearpage

**Body measurements, Part I.** (8.13, p. 316) Researchers studying anthropometry collected body girth measurements and skeletal diameter measurements, as well as age, weight, height and gender for 507 physically active individuals. The scatterplot below shows the relationship between height and shoulder girth (over deltoid muscles), both measured in centimeters.

\begin{center}
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%", fig.height=4}
# load packages -----------------------------------------------------
library(openintro)
# load data ---------------------------------------------------------
data(bdims)
# plot height vs. shoulder girth ------------------------------------
par(mar = c(3.8, 3.8, 0.5, 0.5), las = 1, mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.25, cex.axis = 1.25)
plot(bdims$hgt ~ bdims$sho_gi, 
     xlab = "Shoulder girth (cm)", ylab = "Height (cm)", 
     pch = 19, col = COL[1,2])
```
\end{center}

(a) Describe the relationship between shoulder girth and height.
(b) How would the relationship change if shoulder girth was measured in inches while the units of height remained in centimeters?



## Solution 2

(a)

the relationship between shoulder girth and
height is a linear relationship.

As shoulder girth increases, the height increases as well.


```{r}

lim2 <- lm(bdims$hgt ~ bdims$sho_gi)
print(lim2)

```

Height = 105.8325 + 0.6036*(shoulder girth)


(b)

The relationship would remain linear.
The intercept wouldn't change but the slope would
change since the unit of measure changes. 

See below for illustration.

```{r}

bdims <- bdims %>%
  mutate(sho_gi_in = sho_gi / 2.54)

lm2b <- lm(bdims$hgt ~ bdims$sho_gi_in)

print(lm2b)


plot(bdims$hgt ~ bdims$sho_gi_in, 
     xlab = "Shoulder girth (in)", ylab = "Height (cm)", 
     pch = 19, col = COL[1,2])
```


--------------------------------------------------------------------------------

\clearpage
                                      
**Body measurements, Part III.** (8.24, p. 326) Exercise above introduces data on shoulder girth and height of a group of individuals. The mean shoulder girth is 107.20 cm with a standard deviation of 10.37 cm. The mean height is 171.14 cm with a standard deviation of 9.41 cm. The correlation between height and shoulder girth is 0.67.

(a) Write the equation of the regression line for predicting height.
(b) Interpret the slope and the intercept in this context.
(c) Calculate $R^2$ of the regression line for predicting height from shoulder girth, and interpret it in the context of the application.
(d) A randomly selected student from your class has a shoulder girth of 100 cm. Predict the height of this student using the model.
(e) The student from part (d) is 160 cm tall. Calculate the residual, and explain what this residual means.
(f) A one year old has a shoulder girth of 56 cm. Would it be appropriate to use this linear model to predict the height of this child?


## Solution 3

(a)


```{r}

lim3 <- lm(bdims$hgt ~ bdims$sho_gi)
print(lim3)

```


Height = 105.8325 + 0.6036*(shoulder girth)

(b)

**Slope:** For each additional 1cm of shoulder girth,
we would expect the student height to increase by 0.6036cm

**Intercept:** The height of a student with no shoulder girth is 105.8325cm
(although it is not useful, a person can't have a shoulder girth = 0)


(c)

```{r}
summary(lim3)$r.squared

```

44.3% of the variability in height can be explained by the shoulder girth.


(d)

```{r}
shoulder_girth <- 100
height_100 <- 105.8325 + 0.6036 * shoulder_girth

height_100
```
The predicted height for a student with shoulder girth of 100cm is 166.1925cm

(e)

```{r}

true_height <- 160
pred_height <- height_100

res <- true_height - pred_height
res

```

The model overestimated the height by 6.1925cm

(f)

It wouldn't be appropriate to use this linear model to predict the eight of 
this child. The model was built from students data, 
and predicting a child heght will be far off.
--------------------------------------------------------------------------------

\clearpage

**Cats, Part I.** (8.26, p. 327) The following regression output is for predicting the heart weight (in g) of cats from their body weight (in kg). The coefficients are estimated using a dataset of 144 domestic cats.

\begin{center}
{
\begin{tabular}{rrrrr}
    \hline
            & Estimate  & Std. Error    & t value   & Pr($>$$|$t$|$) \\ 
    \hline
(Intercept) & -0.357    & 0.692         & -0.515    & 0.607 \\ 
body wt     & 4.034     & 0.250         & 16.119    & 0.000 \\ 
    \hline
\end{tabular} \ \\
$s = 1.452 \qquad R^2 = 64.66\% \qquad R^2_{adj} = 64.41\%$ 
}
\end{center}

\begin{center}
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%", fig.height=4}
# load packages -----------------------------------------------------
library(openintro)
library(xtable)
library(MASS)
# load data ---------------------------------------------------------
data(cats)
# model heart weight vs. weight -------------------------------------
m_cats_hwt_bwt <- lm(cats$Hwt ~ cats$Bwt)
# plot heart weight vs. weight --------------------------------------
par(mar = c(3.7, 3.7, 0.5, 0.5), las = 1, mgp = c(2.5, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)
plot(cats$Hwt ~ cats$Bwt, 
     xlab = "Body weight (kg)", ylab = "Heart weight (g)", 
     pch = 19, col = COL[1,2],
     xlim = c(2,4), ylim = c(5, 20.5), axes = FALSE)
axis(1, at = seq(2, 4, 0.5))
axis(2, at = seq(5, 20, 5))
box()
```
\end{center}

(a) Write out the linear model.
(b) Interpret the intercept.
(c) Interpret the slope.
(d) Interpret $R^2$.
(e) Calculate the correlation coefficient.


## Solution 4

(a)

```{r}

# Summary of the model to help answer a-d

lm4 <- lm(cats$Hwt ~ cats$Bwt)
summary(lm4)

```

Heart weight(g) = -0.3567 + 4.0341*(body weight(kg))


(b)

The heart weight(g) of a cat with no body weight is -0.3567
(This is not useful, there is none a cat with 0 body weight or negative 
heart weight).

(c)

For each additional 1kg of cat body weight(kg),
we would expect the heart weight(g) to increase by 4.0341

(d)

64.66% of the variability in heart weight of cats 
can be explained by the body weight.

(e)

```{r}

cor(cats$Bwt, cats$Hwt)

```
The correlation is 0.804

--------------------------------------------------------------------------------

\clearpage

**Rate my professor.** (8.44, p. 340) Many college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously. However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor. Researchers at University of Texas, Austin collected data on teaching evaluation score (higher score means better) and standardized beauty score (a score of 0 means average, negative score means below average, and a positive score means above average) for a sample of 463 professors. The scatterplot below shows the relationship between these variables, and also provided is a regression output for predicting teaching evaluation score from beauty score.

\begin{center}
\begin{tabular}{rrrrr}
    \hline
            & Estimate  & Std. Error    & t value   & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & 4.010     & 0.0255        & 	157.21  & 0.0000 \\ 
beauty      &  \fbox{\textcolor{white}{{ Cell 1}}}  
                        & 0.0322        & 4.13      & 0.0000\vspace{0.8mm} \\ 
   \hline
\end{tabular}


```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%", fig.height=4}
# load packages -----------------------------------------------------
library(openintro)
# load data ---------------------------------------------------------
prof_evals_beauty <- read.csv("https://github.com/jbryer/DATA606Fall2019/raw/master/course_data/prof_evals_beauty.csv")
# rename variables for convenience ----------------------------------
beauty <- prof_evals_beauty$btystdave
eval <- prof_evals_beauty$courseevaluation
# model evaluation scores vs. beauty --------------------------------
m_eval_beauty = lm(eval ~ beauty)
# scatterplot of evaluation scores vs. beauty -----------------------
par(mar = c(3.9, 3.9, 0.5, 0.5), las = 0, mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5, las = 1)
plot(eval ~ beauty, 
     xlab = "Beauty", ylab = "Teaching evaluation", 
     pch = 19, col = COL[1,2], 
     axes = FALSE)
axis(1, at = seq(-1, 2, 1))
axis(2, at = seq(2, 5, 1))
box()
```
\end{center}

(a) Given that the average standardized beauty score is -0.0883 and average teaching evaluation score is 3.9983, calculate the slope. Alternatively, the slope may be computed using just the information provided in the model summary table.
(b) Do these data provide convincing evidence that the slope of the relationship between teaching evaluation and beauty is positive? Explain your reasoning.
(c) List the conditions required for linear regression and check if each one is satisfied for this model based on the following diagnostic plots.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%", fig.height=4}
# residuals plot ----------------------------------------------------
par(mar = c(3.9, 3.9, 0.5, 0.5), las = 0, mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5, las = 1)
plot(m_eval_beauty$residuals ~ beauty, 
     xlab = "Beauty", ylab = "Residuals", 
     pch = 19, col = COL[1,2], 
     ylim = c(-1.82, 1.82), axes = FALSE)
axis(1, at = seq(-1, 2, 1))
axis(2, at = seq(-1, 1, 1))
box()
abline(h = 0, lty = 3)
# residuals histogram -----------------------------------------------
par(mar = c(3.9, 3, 0, 0), cex.lab = 1.5, cex.axis = 1.5)
hist(m_eval_beauty$residuals, 
     xlab = "Residuals", ylab = "", main = "",
     col = COL[1],
     xlim = c(-2,2))
# normal probability plot of residuals ------------------------------
par(mar = c(3.9, 3.9, 0.5, 0.5), mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)
qqnorm(m_eval_beauty$residuals, 
       pch = 19, col = COL[1,2],
       main = "", las = 0)
qqline(m_eval_beauty$residuals, col = COL[1])
# order of residuals ---------------------------------------------===
par(mar = c(3.9, 3.9, 0.5, 0.5), mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)
plot(m_eval_beauty$residuals, 
     xlab = "Order of data collection", ylab = "Residuals", main = "",
     pch = 19, col = COL[1,2],
     ylim = c(-1.82, 1.82), axes = FALSE)
axis(1)
axis(2, at = seq(-1, 1, 1))
box()
abline(h = 0, lty = 3)
```


## Solution 5


(a)

```{r}

lm5 <- lm(eval ~ beauty, data = prof_evals_beauty)

summary(lm5)

```

The slope is 0.133


(b)

A positive slope indicates a positive relationship between teaching evaluation
and beauty. When look at the p_value, it is close to 0 indicating that the 
probability of the slope to be 0 is 0 (null hypothesis and p_value).
Thus, these data provide convincing evidence that 
the slope of the relationship between teaching evaluation and beauty is positive

(c)

The following 

**Linearity:** Residuals ~ Beauty  graph shows a very weak linear
relationship, we can assume the trend of these data is linear.
--> condition satisfied.

**Nearly normal residuals** From the histogram we can see that
the data are left skewed but can be approximated to a nearly normal.
The normal probability plot can also show that the distribution is nearly normal.
--> condition satisfied

**Constant variability:** Residuals ~ Beauty plot shows that points are 
scattered around 0, and I'd say there is a constant variability.
--> condition satisfied.
